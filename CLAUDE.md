# CLAUDE.md - Project AI Guidelines

## State Tracking

**Use two complementary systems for tracking work:**

1. **TodoWrite tool** (primary) - Use for task management visible to the user
   - Break work into discrete, actionable items
   - Mark tasks in_progress/completed as you work
   - Good for: task lists, progress tracking, user visibility

2. **`.claude-current-status` file** (supplementary) - Higher-resolution notes
   - Timestamps, context, decisions, file references
   - Details that don't fit in todo items
   - Session continuity across conversations
   - Good for: debugging context, decision rationale, file locations

**Workflow:** Start tasks with TodoWrite, always add detailed notes to `.claude-current-status`. When you add notes, re-assess and clean up old notes.

**New Status Management Commands:**
- `/continue` - Efficiently resume work by extracting recent session context
- `/condense [N]` - Archive old content, keep last N lines (default: 200)
- `scripts/status-helper.sh` - Auto-cleanup helper for updates

**Auto-Cleanup Pattern:** When updating `.claude-current-status`, check if file exceeds 300 lines and consider running `/condense`.

**CRITICAL: Always Append to .claude-current-status**
- **ALWAYS use `>>` (append) when adding new content** - New sessions, updates, and notes must be appended to the end of the file
- **NEVER use `>` (overwrite) or prepend** - Prepending causes recent work to be archived by `/condense`, losing context
- **Correct pattern**: `echo "## Session Start - $(date)" >> .claude-current-status`
- **Incorrect pattern**: `cat new_content.md .claude-current-status > temp && mv temp .claude-current-status` (prepends)
- **Verification**: Ensure newest timestamps are at the bottom of the file, oldest at the top
- **If `/continue` misses recent work**: Check `.claude-archive/` for recently archived content


## Project Overview

This project models PhD unemployment rates relative to sensible baselines (general unemployment, other graduate degrees) using:

- **Languages**: R and Stan (via brms, cmdstanr)
- **Data source**: IPUMS (https://usa.ipums.org/usa/index.shtml)
- **Development environment**: RStudio Quarto Docker container
- **Statistical approach**: Simplest models allowing maximum disaggregation
  - Multiple seasonal components
  - GAMs, Gaussian processes, autocorrelation for dense time series
- **Communication goal**: Clear TDD process documentation and beautiful visualization of insights

## CRITICAL: Docker Environment Requirement

**ALWAYS check environment at session start:**

```bash
npm run env:check
```

This project MUST be developed inside the RStudio Quarto Docker container. The script above will:
- Verify you're in the Docker container
- Check R, RStudio Server, and Quarto are available
- Validate required R packages are installed

If not in the container, the script will show connection instructions.

## Development Method: TDD

**RECOMMENDED: Use Test-Driven Development for new features**

TDD helps Claude produce more focused, correct code by clarifying requirements upfront and reducing wildly wrong approaches.

### Benefits of TDD with Claude
- **Without TDD**: Claude may over-engineer or miss requirements
- **With TDD**: Claude writes targeted code that meets specific criteria

### TDD Workflow
1. üî¥ **RED**: Write a failing test to define requirements
2. üü¢ **GREEN**: Write minimal code to pass the test
3. üîÑ **REFACTOR**: Improve code with test safety net
4. ‚úì **COMMIT**: Ship working, tested code

### The TDD Command
```bash
/tdd start "your feature"  # Guides through the TDD cycle
```

Consider TDD especially for complex features or when requirements are unclear.

## Critical Instructions

**ALWAYS use `date` command for dates** - Never assume or guess dates. Always run `date "+%Y-%m-%d"` when you need the current date for documentation, commits, or any other purpose.

**ALWAYS save CmdStan fits with CSV files** - NEVER use `qsave()` or `saveRDS()` directly on cmdstanr fit objects. ALWAYS use `save_cmdstan_fit()` to preserve CSV files. Without CSV files, the fit objects become unusable (cannot extract summaries, draws, or diagnostics). See `CMDSTAN_SAVE_CRITICAL.md` for details.

```r
# ‚ùå WRONG - CSV files will be lost
qsave(result, "models/fit.qs")

# ‚úÖ CORRECT - CSV files preserved
save_cmdstan_fit(result, "models/fit.qs")
```

## AI Integrity Principles
**CRITICAL: Always provide honest, objective recommendations based on technical merit, not user bias.**

- **Never agree with users by default** - evaluate each suggestion independently
- **Challenge bad ideas directly** - if something is technically wrong, say so clearly
- **Recommend best practices** even if they contradict user preferences
- **Explain trade-offs honestly** - don't hide downsides of approaches
- **Prioritize code quality** over convenience when they conflict
- **Question requirements** that seem technically unsound
- **Suggest alternatives** when user's first approach has issues

Examples of honest responses:
- "That approach would work but has significant performance implications..."
- "I'd recommend against that pattern because..."
- "While that's possible, a better approach would be..."
- "That's technically feasible but violates [principle] because..."

## Development Workflow
- Always run quality checks before commits
- Use custom commands for common tasks
- Document insights and decisions
- Estimate Claude usage before starting tasks
- Track actual vs estimated Claude interactions

## Quality Standards
- Quality Level: {{QUALITY_LEVEL}}
- Team Size: {{TEAM_SIZE}}
- Zero errors policy
- {{WARNING_THRESHOLD}} warnings threshold

## Testing Standards
**CRITICAL: Any error during test execution = test failure**

### R Testing with testthat
- **Zero tolerance for test errors** - All tests must pass, warnings should be addressed
- **Unit tests for functions** - Test data processing, transformation functions
- **Statistical tests** - Verify model convergence, parameter estimates within expected ranges
- **Data validation tests** - Ensure data integrity and proper preprocessing
- **Model comparison tests** - Compare nested models, validate model selection criteria
- **Performance budgets** - Long-running Stan models should have timeout limits

### Testing Workflow
- Use `npm run test:r` to run R tests via testthat
- Use `npm run r:test` for development testing with devtools
- Keep test execution time reasonable (<2 min for unit tests)
- Use mock data for rapid iteration, real data for validation

## Markdown Standards
**All markdown files must pass validation before commit**

- **Syntax validation** - Uses remark-lint to ensure valid markdown syntax
- **Consistent formatting** - Enforces consistent list markers, emphasis, and code blocks
- **Link validation** - Checks that internal links point to existing files
- **Auto-fix available** - Run `npm run markdown:fix` to auto-correct formatting issues

### Markdown Quality Checks
- `npm run markdown:lint` - Validate all markdown files
- `npm run markdown:fix` - Auto-fix formatting issues
- Included in `hygiene:quick` and `commit:check` scripts
- CI validates markdown on every push/PR

### Markdown Style Guidelines
- Use `-` for unordered lists
- Use `*` for emphasis, `**` for strong emphasis
- Use fenced code blocks with language tags
- Use `.` for ordered list markers
- Ensure all internal links are valid

## Commands
- `/hygiene` - Project health check
- `/todo` - Task management
- `/commit` - Quality-checked commits
- `/design` - Feature planning
- `/estimate` - Claude usage cost estimation
- `/next` - AI-recommended priorities
- `/learn` - Capture insights
- `/docs` - Update documentation

## Architecture Principles

### R Code Standards
- Keep functions focused and testable (< 50 lines preferred)
- R script files under 400 lines
- Comprehensive error handling with informative messages
- **Prefer base R and data.table over tidyverse**
  - Use base R for core operations (subsetting, transformations)
  - Use data.table for efficient operations on large datasets (millions of rows)
  - Avoid tidyverse/dplyr unless specifically beneficial
  - Rationale: Fewer dependencies, better performance for CPS data
- Document functions with roxygen2 comments
- Avoid global state, use function parameters

#### Data Manipulation Examples
```r
# Preferred: data.table
library(data.table)
dt <- as.data.table(cps_data)
dt[EDUC == 125, .(unemp_rate = weighted.mean(EMPSTAT == 2, WTFINL)),
   by = .(YEAR, MONTH)]

# Acceptable: base R
cps_phd <- cps_data[cps_data$EDUC == 125, ]
aggregate(EMPSTAT ~ YEAR + MONTH, data = cps_phd, FUN = mean)

# Avoid: tidyverse
# library(dplyr)
# cps_data %>% filter(EDUC == 125) %>% ...
```

### Statistical Modeling Standards
- Start with simplest model, add complexity incrementally
- Always check model convergence diagnostics (Rhat, ESS)
- Validate prior choices with prior predictive checks
- Perform posterior predictive checks
- Compare models using LOO-CV or WAIC
- Document model assumptions and limitations

## Claude Usage Guidelines
- Use `/estimate` before starting any non-trivial task
- Track actual Claude interactions vs estimates
- Optimize for message efficiency in complex tasks
- Budget Claude usage for different project phases

**Typical Usage Patterns**:
- **Bug Fix**: 10-30 messages
- **Small Feature**: 30-80 messages  
- **Major Feature**: 100-300 messages
- **Architecture Change**: 200-500 messages

## Collaboration Guidelines
- Always add Claude as co-author on commits
- Run `/hygiene` before asking for help
- Use `/todo` for quick task capture
- Document learnings with `/learn`
- Regular `/reflect` sessions for insights

## Project Standards
- Test coverage: 60% minimum for R functions
- Documentation: All functions documented with roxygen2
- Error handling: Graceful failures with clear messages
- Performance: Monitor code complexity and file sizes
- Reproducibility: Use renv for R package management
- Data provenance: Document data sources and transformations
- Model artifacts: Save models with metadata (date, version, convergence stats)
- ALWAYS use atomic commits
- Use emojis judiciously
- NEVER Edit() a file before you Read() the file

## R Project Structure
- `R/` - R functions and utilities
- `tests/testthat/` - Unit tests for R functions
- `data/` - Processed data files (RDS, parquet)
- `data-raw/` - Raw data and processing scripts
- `models/` - Saved Stan models and fitted objects
- `reports/` - Quarto documents and analysis notebooks
- `stan/` - Stan model files (.stan)
- `DESCRIPTION` - R package metadata
- `NAMESPACE` - R package namespace (auto-generated)

## Quarto Report Standards
**CRITICAL: NO caching in Quarto documents**

- **Keep model code in reports** - Always include the model fitting code directly in Quarto reports, not just loading from external functions. This makes the model specification visible and auditable.
- **Never use `cache=TRUE`** - Caching is disabled project-wide for reproducibility
- **Always re-run from scratch** - Every render should execute all code chunks fresh
- **Reproducibility priority** - Ensures reports always reflect current code state
- **Session info required** - Include `sessionInfo()` at end of all reports
- **Seed documentation** - Document random seeds for reproducible simulations
- **Dependencies explicit** - Load all required packages in setup chunk

### TDD Examples

- [üî¥ test: add failing test for updateCommandCatalog isolation (TDD RED)](../../commit/00e7a22)
- [üî¥ test: add failing tests for tdd.js framework detection (TDD RED)](../../commit/2ce43d1)
- [üî¥ test: add failing tests for learn.js functions (TDD RED)](../../commit/8b90d58)
- [üî¥ test: add failing tests for formatBytes and estimateTokens (TDD RED)](../../commit/1fdac58)
- [üî¥ test: add failing tests for findBrokenLinks (TDD RED phase)](../../commit/8ec6319)
