# Learnings - 2025-11

## 2025-11-12 - 04:43
Coverage validation requires different approaches for prediction intervals vs parameter CIs. Prediction intervals: fit ONE reference model, test on MANY new datasets. Parameter CIs: fit MANY new models, check if each CI contains true value. Mixing these approaches (e.g., fitting new models and testing on their own training data) gives artificially perfect 100% coverage.

## 2025-11-12 - 04:43
DGP consistency is critical for coverage validation. The data-generating process used to create reference data MUST exactly match the DGP used in validation simulations. Any parameter mismatch (e.g., trend_slope) creates systematic bias and miscalibrated coverage, even when using default parameters.

## 2025-11-12 - 04:43
When validation functions use default parameters, document them explicitly in reports. Users must understand that omitting a parameter (like trend_slope) from true_params doesn't mean 'use whatever was in the data' - it means 'use the function's default value'. This caused a 73% to 94% coverage fix when we aligned reference data's trend_slope=0.0003 to match the function's default of trend_slope=0.

## 2025-11-12 - 04:43
Validation reports benefit from explicit 'What We're Comparing' sections that state: (1) the exact DGP with all parameter values, (2) the fitted model type, and (3) the step-by-step test procedure. This clarity prevents bugs like testing models on their own training data and helps readers understand the validation logic.

## 2025-11-16 - 00:54
TDD gap: Thought I implemented shared smoothing constraints with TDD, but never actually wrote tests to verify it. The implementation in fit_nested_model_sequence() was missing id= parameters despite report claiming to use them. Tests would have caught this immediately. Lesson: TDD intent doesn't equal TDD execution - always verify tests actually exist and cover the claimed functionality.

## 2025-11-17 - 04:37
Quarto caching: Avoid chunk caching in QMD files - it creates unsafe dependencies between chunks and breaks reproducibility. User never uses caching in non-AI-assisted work. If chunks need to share data, restructure code to be self-contained or use explicit file-based persistence instead of relying on cached variables.

## 2025-11-17 - 04:38
Build optimization workflow: Instead of Quarto chunk caching for performance, use a Make-like workflow with explicit file-based dependencies. This provides reproducible builds with proper dependency tracking - intermediate results saved to files, targets only rebuilt when dependencies change. More reliable than chunk caching and aligns with standard build system patterns.

